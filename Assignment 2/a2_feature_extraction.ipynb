{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21c59683-b5ba-4d0b-9127-71b37a0265c3",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTIONS\n",
    "- voice_position-to-predicate\n",
    "- predicate-lemma_pos\n",
    "- PoS of each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c28525-9a08-4df6-b4c0-263477751922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9cf5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    '''Function for extracting features,\n",
    "    - token's voice (based on dependency relation tags) & its position to predicate,\n",
    "    - predicate lemma and its pos tag\n",
    "    - pos tag of each token\n",
    "    :param inputfile: string, file path\n",
    "\n",
    "    :return a list of dictionaries\n",
    "    '''\n",
    "    #read in data to a pandas dataframe\n",
    "\n",
    "    train_df = pd.read_csv(file_path, sep='\\t', header=0, encoding='utf-8', quotechar='â„–')\n",
    "\n",
    "    # change values in columns 'sent_id, Copy_ID, id' to integer\n",
    "    train_df = train_df.astype({'Sent_ID':'int'})\n",
    "    train_df = train_df.astype({'Copy_ID':'int'})\n",
    "    train_df = train_df.astype({'ID':'int'})\n",
    "\n",
    "    features_dict_list = []\n",
    "\n",
    "    copy_id_list = train_df['Copy_ID'].unique()\n",
    "    \n",
    "    for num in copy_id_list:\n",
    "        df_copy = train_df.loc[train_df['Copy_ID'] == num] # subset df for each sentence\n",
    "\n",
    "        # get the length of sentence\n",
    "        max_wds_count = df_copy['ID'].max()\n",
    "\n",
    "        #find ID value of the predicate\n",
    "        # pred_row = df_copy.loc[df_copy['UP:PRED']!= '_']\n",
    "        # pred_id = pred_row['ID']\n",
    "        pred_item = df_copy['ID'][df_copy['UP:PRED'].str.len() > 2]\n",
    "        pred_id = None\n",
    "        try:\n",
    "            pred_id = pred_item.values[0]\n",
    "        except Exception as err:\n",
    "            print(' !!! WARNING !!! There is no predicate in sentence with copy_id:', num)\n",
    "            continue\n",
    "\n",
    "        print(\"pred_id:\",pred_id)\n",
    "        print(\"type pred_id:\", type(pred_id))\n",
    "\n",
    "        # create a new column \"VOICE\" and set all values to \"0\"\n",
    "        df_copy['VOICE'] = '0' \n",
    "\n",
    "        # extract features within each sentence boundary\n",
    "        for i in range(max_wds_count):\n",
    "            features_dict = {}\n",
    "            \n",
    "            # row 'i'\n",
    "            df_row = df_copy.iloc[i]\n",
    "\n",
    "            # extract each token\n",
    "            features_dict['token']=df_row['FORM']\n",
    "            \n",
    "            # extract POS, ALL TOKENS\n",
    "            features_dict['pos'] = df_row['XPOS']\n",
    "\n",
    "            # extract VOICE + POSITION TO PREDICATE\n",
    "            if df_row['DEPREL'] == 'nsubj:pass':\n",
    "                \n",
    "                if i < (pred_id - 1):\n",
    "                    df_row['VOICE'] = '1_before'\n",
    "                elif i > (pred_id-1):\n",
    "                    df_row['VOICE'] = '1_after'\n",
    "                else:\n",
    "                    df_row['VOICE'] = '1_same'\n",
    "            else:\n",
    "                if i < (pred_id-1):\n",
    "                    df_row['VOICE'] = '0_before'\n",
    "                elif i > (pred_id-1):\n",
    "                    df_row['VOICE'] = '0_after'\n",
    "                else:\n",
    "                    df_row['VOICE'] = '0_same'\n",
    "\n",
    "            features_dict['voice_position-to-pred'] = df_row['VOICE']\n",
    "\n",
    "            # extract PREDICATE LEMMA + POS TAG\n",
    "            if i == (pred_id - 1):\n",
    "                features_dict['pred-lemma_pos'] = f\"{df_row['LEMMA']}_{df_row['XPOS']}\"\n",
    "            \n",
    "            features_dict_list.append(features_dict) \n",
    "        \n",
    "    return features_dict_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0cfca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = '../data/train_split.tsv'\n",
    "# features_list = extract_features(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
