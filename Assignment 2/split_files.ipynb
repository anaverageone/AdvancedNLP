{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes there are up to 35 predicates in one sentence in the training data\n",
    "header = ['ID','FORM','LEMMA','UPOS','XPOS','FEATS','HEAD','DEPREL','DEPS','MISC','UP:PRED','UP:ARGHEADS_1','UP:ARGHEADS_2','UP:ARGHEADS_3','UP:ARGHEADS_4','UP:ARGHEADS_5','UP:ARGHEADS_6','UP:ARGHEADS_7','UP:ARGHEADS_8','UP:ARGHEADS_9','UP:ARGHEADS_10','UP:ARGHEADS_11','UP:ARGHEADS_12','UP:ARGHEADS_13','UP:ARGHEADS_14','UP:ARGHEADS_15','UP:ARGHEADS_16','UP:ARGHEADS_17','UP:ARGHEADS_18','UP:ARGHEADS_19','UP:ARGHEADS_20','UP:ARGHEADS_21','UP:ARGHEADS_22','UP:ARGHEADS_23','UP:ARGHEADS_24','UP:ARGHEADS_25','UP:ARGHEADS_26','UP:ARGHEADS_27','UP:ARGHEADS_28','UP:ARGHEADS_29','UP:ARGHEADS_30','UP:ARGHEADS_31','UP:ARGHEADS_32','UP:ARGHEADS_33','UP:ARGHEADS_34','UP:ARGHEADS_35']\n",
    "# header names taken from: \n",
    "# https://universaldependencies.org/format.html\n",
    "# https://universalpropositions.github.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID      FORM     LEMMA   UPOS   XPOS  \\\n",
      "0        1.0        Al        Al  PROPN    NNP   \n",
      "1        2.0         -         -  PUNCT   HYPH   \n",
      "2        3.0     Zaman     Zaman  PROPN    NNP   \n",
      "3        4.0         :         :  PUNCT      :   \n",
      "4        5.0  American  american    ADJ     JJ   \n",
      "...      ...       ...       ...    ...    ...   \n",
      "202254  22.0        on        on    ADP     IN   \n",
      "202255  23.0        my        my   PRON   PRP$   \n",
      "202256  24.0       car       car   NOUN     NN   \n",
      "202257  25.0         )         )  PUNCT  -RRB-   \n",
      "202258  26.0         .         .  PUNCT      .   \n",
      "\n",
      "                                             FEATS HEAD     DEPREL  \\\n",
      "0                                      Number=Sing    0       root   \n",
      "1                                                _    1      punct   \n",
      "2                                      Number=Sing    1       flat   \n",
      "3                                                _    1      punct   \n",
      "4                                       Degree=Pos    6       amod   \n",
      "...                                            ...  ...        ...   \n",
      "202254                                           _   24       case   \n",
      "202255  Number=Sing|Person=1|Poss=Yes|PronType=Prs   24  nmod:poss   \n",
      "202256                                 Number=Sing   21        obl   \n",
      "202257                                           _    4      punct   \n",
      "202258                                           _    4      punct   \n",
      "\n",
      "                DEPS           MISC  ... UP:ARGHEADS_26 UP:ARGHEADS_27  \\\n",
      "0             0:root  SpaceAfter=No  ...            NaN            NaN   \n",
      "1            1:punct  SpaceAfter=No  ...            NaN            NaN   \n",
      "2             1:flat              _  ...            NaN            NaN   \n",
      "3            1:punct              _  ...            NaN            NaN   \n",
      "4             6:amod              _  ...            NaN            NaN   \n",
      "...              ...            ...  ...            ...            ...   \n",
      "202254       24:case              _  ...            NaN            NaN   \n",
      "202255  24:nmod:poss              _  ...            NaN            NaN   \n",
      "202256     21:obl:on  SpaceAfter=No  ...            NaN            NaN   \n",
      "202257       4:punct  SpaceAfter=No  ...            NaN            NaN   \n",
      "202258       4:punct              _  ...            NaN            NaN   \n",
      "\n",
      "       UP:ARGHEADS_28 UP:ARGHEADS_29 UP:ARGHEADS_30 UP:ARGHEADS_31  \\\n",
      "0                 NaN            NaN            NaN            NaN   \n",
      "1                 NaN            NaN            NaN            NaN   \n",
      "2                 NaN            NaN            NaN            NaN   \n",
      "3                 NaN            NaN            NaN            NaN   \n",
      "4                 NaN            NaN            NaN            NaN   \n",
      "...               ...            ...            ...            ...   \n",
      "202254            NaN            NaN            NaN            NaN   \n",
      "202255            NaN            NaN            NaN            NaN   \n",
      "202256            NaN            NaN            NaN            NaN   \n",
      "202257            NaN            NaN            NaN            NaN   \n",
      "202258            NaN            NaN            NaN            NaN   \n",
      "\n",
      "       UP:ARGHEADS_32 UP:ARGHEADS_33 UP:ARGHEADS_34 UP:ARGHEADS_35  \n",
      "0                 NaN            NaN            NaN            NaN  \n",
      "1                 NaN            NaN            NaN            NaN  \n",
      "2                 NaN            NaN            NaN            NaN  \n",
      "3                 NaN            NaN            NaN            NaN  \n",
      "4                 NaN            NaN            NaN            NaN  \n",
      "...               ...            ...            ...            ...  \n",
      "202254            NaN            NaN            NaN            NaN  \n",
      "202255            NaN            NaN            NaN            NaN  \n",
      "202256            NaN            NaN            NaN            NaN  \n",
      "202257            NaN            NaN            NaN            NaN  \n",
      "202258            NaN            NaN            NaN            NaN  \n",
      "\n",
      "[202259 rows x 46 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nurbe\\AppData\\Local\\Temp\\ipykernel_11048\\1627027910.py:3: DtypeWarning: Columns (26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(train_path, sep='\\t', comment='#', names=header)\n"
     ]
    }
   ],
   "source": [
    "train_path = '../data/en_ewt-up-train.conllu'\n",
    "train_df = pd.read_csv(train_path, sep='\\t', comment='#', names=header)\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens that are at the beginning of each sentence\n",
    "start_of_sent = train_df.index[train_df['ID'] == 1 ].tolist()\n",
    "# get sentence IDs for each sentence\n",
    "def sent(row, list_firsts):\n",
    "    for ix, first in enumerate(list_firsts):\n",
    "        if row.name == first:\n",
    "            sent_num = ix+1\n",
    "            return sent_num\n",
    "\n",
    "train_df['Sent_ID'] = train_df.apply(lambda row: sent(row, start_of_sent), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Sent_ID    ID      FORM     LEMMA   UPOS   XPOS  \\\n",
      "0           1.0   1.0        Al        Al  PROPN    NNP   \n",
      "1           1.0   2.0         -         -  PUNCT   HYPH   \n",
      "2           1.0   3.0     Zaman     Zaman  PROPN    NNP   \n",
      "3           1.0   4.0         :         :  PUNCT      :   \n",
      "4           1.0   5.0  American  american    ADJ     JJ   \n",
      "...         ...   ...       ...       ...    ...    ...   \n",
      "202254  12456.0  22.0        on        on    ADP     IN   \n",
      "202255  12456.0  23.0        my        my   PRON   PRP$   \n",
      "202256  12456.0  24.0       car       car   NOUN     NN   \n",
      "202257  12456.0  25.0         )         )  PUNCT  -RRB-   \n",
      "202258  12456.0  26.0         .         .  PUNCT      .   \n",
      "\n",
      "                                             FEATS HEAD     DEPREL  \\\n",
      "0                                      Number=Sing    0       root   \n",
      "1                                                _    1      punct   \n",
      "2                                      Number=Sing    1       flat   \n",
      "3                                                _    1      punct   \n",
      "4                                       Degree=Pos    6       amod   \n",
      "...                                            ...  ...        ...   \n",
      "202254                                           _   24       case   \n",
      "202255  Number=Sing|Person=1|Poss=Yes|PronType=Prs   24  nmod:poss   \n",
      "202256                                 Number=Sing   21        obl   \n",
      "202257                                           _    4      punct   \n",
      "202258                                           _    4      punct   \n",
      "\n",
      "                DEPS  ... UP:ARGHEADS_26 UP:ARGHEADS_27 UP:ARGHEADS_28  \\\n",
      "0             0:root  ...            NaN            NaN            NaN   \n",
      "1            1:punct  ...            NaN            NaN            NaN   \n",
      "2             1:flat  ...            NaN            NaN            NaN   \n",
      "3            1:punct  ...            NaN            NaN            NaN   \n",
      "4             6:amod  ...            NaN            NaN            NaN   \n",
      "...              ...  ...            ...            ...            ...   \n",
      "202254       24:case  ...            NaN            NaN            NaN   \n",
      "202255  24:nmod:poss  ...            NaN            NaN            NaN   \n",
      "202256     21:obl:on  ...            NaN            NaN            NaN   \n",
      "202257       4:punct  ...            NaN            NaN            NaN   \n",
      "202258       4:punct  ...            NaN            NaN            NaN   \n",
      "\n",
      "       UP:ARGHEADS_29 UP:ARGHEADS_30 UP:ARGHEADS_31 UP:ARGHEADS_32  \\\n",
      "0                 NaN            NaN            NaN            NaN   \n",
      "1                 NaN            NaN            NaN            NaN   \n",
      "2                 NaN            NaN            NaN            NaN   \n",
      "3                 NaN            NaN            NaN            NaN   \n",
      "4                 NaN            NaN            NaN            NaN   \n",
      "...               ...            ...            ...            ...   \n",
      "202254            NaN            NaN            NaN            NaN   \n",
      "202255            NaN            NaN            NaN            NaN   \n",
      "202256            NaN            NaN            NaN            NaN   \n",
      "202257            NaN            NaN            NaN            NaN   \n",
      "202258            NaN            NaN            NaN            NaN   \n",
      "\n",
      "       UP:ARGHEADS_33 UP:ARGHEADS_34 UP:ARGHEADS_35  \n",
      "0                 NaN            NaN            NaN  \n",
      "1                 NaN            NaN            NaN  \n",
      "2                 NaN            NaN            NaN  \n",
      "3                 NaN            NaN            NaN  \n",
      "4                 NaN            NaN            NaN  \n",
      "...               ...            ...            ...  \n",
      "202254            NaN            NaN            NaN  \n",
      "202255            NaN            NaN            NaN  \n",
      "202256            NaN            NaN            NaN  \n",
      "202257            NaN            NaN            NaN  \n",
      "202258            NaN            NaN            NaN  \n",
      "\n",
      "[202259 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "# move the sentence number column to the front\n",
    "# adapted from: https://stackoverflow.com/questions/25122099/move-column-by-name-to-front-of-table-in-pandas\n",
    "cols = list(train_df)\n",
    "cols.insert(0,cols.pop(cols.index('Sent_ID')))\n",
    "train_df = train_df.loc[:,cols]\n",
    "# fill NaN values for all tokens that are not at the beginning of the sentence\n",
    "train_df.Sent_ID.ffill(inplace=True)\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by sentences\n",
    "sentences = train_df.groupby(['Sent_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_split_df = ['Sent_ID','ID','FORM','LEMMA','UPOS','XPOS','FEATS','HEAD','DEPREL','DEPS','MISC','UP:PRED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the new df to store splitted data in\n",
    "# start with the first sentence (based on the fact that we know it only has one predicate in it)\n",
    "first = sentences.get_group(1)\n",
    "pred = first['UP:PRED'].nunique()\n",
    "new_train = first.filter(items=header_split_df)\n",
    "new_train['UP:ARGHEADS'] = first['UP:ARGHEADS_1']\n",
    "# print(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through grouped sentences\n",
    "for name, sentence in sentences:\n",
    "    if name == 1: # skip the first sentence\n",
    "        continue\n",
    "    predicates = sentence['UP:PRED'].nunique()\n",
    "    if predicates <= 2:\n",
    "        sentence_df = sentence.filter(items=header_split_df)\n",
    "        sentence_df['UP:ARGHEADS'] = sentence['UP:ARGHEADS_1']\n",
    "        new_train = pd.concat([new_train,sentence_df])\n",
    "    else:\n",
    "        for i in range(predicates-1):\n",
    "            sentence_df = sentence.filter(items=header_split_df)\n",
    "            sentence_df['UP:ARGHEADS'] = sentence[f'UP:ARGHEADS_{i+1}']\n",
    "            new_train = pd.concat([new_train,sentence_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a tsv file\n",
    "new_train.to_csv('../data/train_split.tsv',sep='\\t',header=0,index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID        FORM     LEMMA   UPOS XPOS  \\\n",
      "0       1.0        What      what   PRON   WP   \n",
      "1       2.0          if        if  SCONJ   IN   \n",
      "2       3.0      Google    Google  PROPN  NNP   \n",
      "3       4.0     Morphed     morph   VERB  VBD   \n",
      "4       5.0        Into      into    ADP   IN   \n",
      "...     ...         ...       ...    ...  ...   \n",
      "25092  16.0  suggesting   suggest   VERB  VBG   \n",
      "25093  17.0   exercises  exercise   NOUN  NNS   \n",
      "25094  18.0          to        to   PART   TO   \n",
      "25095  19.0         use       use   VERB   VB   \n",
      "25096  20.0           .         .  PUNCT    .   \n",
      "\n",
      "                                  FEATS HEAD DEPREL                   DEPS  \\\n",
      "0                          PronType=Int    0   root                 0:root   \n",
      "1                                     _    4   mark                 4:mark   \n",
      "2                           Number=Sing    4  nsubj                4:nsubj   \n",
      "3      Mood=Ind|Tense=Past|VerbForm=Fin    1  advcl             1:advcl:if   \n",
      "4                                     _    6   case                 6:case   \n",
      "...                                 ...  ...    ...                    ...   \n",
      "25092                      VerbForm=Ger    7   conj  5:advcl:in|7:conj:and   \n",
      "25093                       Number=Plur   16    obj                 16:obj   \n",
      "25094                                 _   19   mark                19:mark   \n",
      "25095                      VerbForm=Inf   17    acl              17:acl:to   \n",
      "25096                                 _    2  punct                2:punct   \n",
      "\n",
      "                MISC  ... UP:ARGHEADS_26 UP:ARGHEADS_27 UP:ARGHEADS_28  \\\n",
      "0                  _  ...            NaN            NaN            NaN   \n",
      "1                  _  ...            NaN            NaN            NaN   \n",
      "2                  _  ...            NaN            NaN            NaN   \n",
      "3                  _  ...            NaN            NaN            NaN   \n",
      "4                  _  ...            NaN            NaN            NaN   \n",
      "...              ...  ...            ...            ...            ...   \n",
      "25092              _  ...            NaN            NaN            NaN   \n",
      "25093              _  ...            NaN            NaN            NaN   \n",
      "25094              _  ...            NaN            NaN            NaN   \n",
      "25095  SpaceAfter=No  ...            NaN            NaN            NaN   \n",
      "25096              _  ...            NaN            NaN            NaN   \n",
      "\n",
      "      UP:ARGHEADS_29 UP:ARGHEADS_30 UP:ARGHEADS_31 UP:ARGHEADS_32  \\\n",
      "0                NaN            NaN            NaN            NaN   \n",
      "1                NaN            NaN            NaN            NaN   \n",
      "2                NaN            NaN            NaN            NaN   \n",
      "3                NaN            NaN            NaN            NaN   \n",
      "4                NaN            NaN            NaN            NaN   \n",
      "...              ...            ...            ...            ...   \n",
      "25092            NaN            NaN            NaN            NaN   \n",
      "25093            NaN            NaN            NaN            NaN   \n",
      "25094            NaN            NaN            NaN            NaN   \n",
      "25095            NaN            NaN            NaN            NaN   \n",
      "25096            NaN            NaN            NaN            NaN   \n",
      "\n",
      "      UP:ARGHEADS_33 UP:ARGHEADS_34 UP:ARGHEADS_35  \n",
      "0                NaN            NaN            NaN  \n",
      "1                NaN            NaN            NaN  \n",
      "2                NaN            NaN            NaN  \n",
      "3                NaN            NaN            NaN  \n",
      "4                NaN            NaN            NaN  \n",
      "...              ...            ...            ...  \n",
      "25092            NaN            NaN            NaN  \n",
      "25093            NaN            NaN            NaN  \n",
      "25094            NaN            NaN            NaN  \n",
      "25095            NaN            NaN            NaN  \n",
      "25096            NaN            NaN            NaN  \n",
      "\n",
      "[25097 rows x 46 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nurbe\\AppData\\Local\\Temp\\ipykernel_11048\\2668279215.py:2: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_df = pd.read_csv(test_path, sep='\\t', comment='#', names=header)\n"
     ]
    }
   ],
   "source": [
    "test_path = '../data/en_ewt-up-test.conllu'\n",
    "test_df = pd.read_csv(test_path, sep='\\t', comment='#', names=header)\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens that are at the beginning of each sentence\n",
    "start_of_sent_test = test_df.index[test_df['ID'] == 1 ].tolist()\n",
    "# get sentence IDs for each sentence\n",
    "def sent(row, list_firsts):\n",
    "    for ix, first in enumerate(list_firsts):\n",
    "        if row.name == first:\n",
    "            sent_num = ix+1\n",
    "            return sent_num\n",
    "\n",
    "test_df['Sent_ID'] = test_df.apply(lambda row: sent(row, start_of_sent_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Sent_ID    ID        FORM     LEMMA   UPOS XPOS  \\\n",
      "0          1.0   1.0        What      what   PRON   WP   \n",
      "1          1.0   2.0          if        if  SCONJ   IN   \n",
      "2          1.0   3.0      Google    Google  PROPN  NNP   \n",
      "3          1.0   4.0     Morphed     morph   VERB  VBD   \n",
      "4          1.0   5.0        Into      into    ADP   IN   \n",
      "...        ...   ...         ...       ...    ...  ...   \n",
      "25092   2077.0  16.0  suggesting   suggest   VERB  VBG   \n",
      "25093   2077.0  17.0   exercises  exercise   NOUN  NNS   \n",
      "25094   2077.0  18.0          to        to   PART   TO   \n",
      "25095   2077.0  19.0         use       use   VERB   VB   \n",
      "25096   2077.0  20.0           .         .  PUNCT    .   \n",
      "\n",
      "                                  FEATS HEAD DEPREL                   DEPS  \\\n",
      "0                          PronType=Int    0   root                 0:root   \n",
      "1                                     _    4   mark                 4:mark   \n",
      "2                           Number=Sing    4  nsubj                4:nsubj   \n",
      "3      Mood=Ind|Tense=Past|VerbForm=Fin    1  advcl             1:advcl:if   \n",
      "4                                     _    6   case                 6:case   \n",
      "...                                 ...  ...    ...                    ...   \n",
      "25092                      VerbForm=Ger    7   conj  5:advcl:in|7:conj:and   \n",
      "25093                       Number=Plur   16    obj                 16:obj   \n",
      "25094                                 _   19   mark                19:mark   \n",
      "25095                      VerbForm=Inf   17    acl              17:acl:to   \n",
      "25096                                 _    2  punct                2:punct   \n",
      "\n",
      "       ... UP:ARGHEADS_26 UP:ARGHEADS_27 UP:ARGHEADS_28 UP:ARGHEADS_29  \\\n",
      "0      ...            NaN            NaN            NaN            NaN   \n",
      "1      ...            NaN            NaN            NaN            NaN   \n",
      "2      ...            NaN            NaN            NaN            NaN   \n",
      "3      ...            NaN            NaN            NaN            NaN   \n",
      "4      ...            NaN            NaN            NaN            NaN   \n",
      "...    ...            ...            ...            ...            ...   \n",
      "25092  ...            NaN            NaN            NaN            NaN   \n",
      "25093  ...            NaN            NaN            NaN            NaN   \n",
      "25094  ...            NaN            NaN            NaN            NaN   \n",
      "25095  ...            NaN            NaN            NaN            NaN   \n",
      "25096  ...            NaN            NaN            NaN            NaN   \n",
      "\n",
      "      UP:ARGHEADS_30 UP:ARGHEADS_31 UP:ARGHEADS_32 UP:ARGHEADS_33  \\\n",
      "0                NaN            NaN            NaN            NaN   \n",
      "1                NaN            NaN            NaN            NaN   \n",
      "2                NaN            NaN            NaN            NaN   \n",
      "3                NaN            NaN            NaN            NaN   \n",
      "4                NaN            NaN            NaN            NaN   \n",
      "...              ...            ...            ...            ...   \n",
      "25092            NaN            NaN            NaN            NaN   \n",
      "25093            NaN            NaN            NaN            NaN   \n",
      "25094            NaN            NaN            NaN            NaN   \n",
      "25095            NaN            NaN            NaN            NaN   \n",
      "25096            NaN            NaN            NaN            NaN   \n",
      "\n",
      "      UP:ARGHEADS_34 UP:ARGHEADS_35  \n",
      "0                NaN            NaN  \n",
      "1                NaN            NaN  \n",
      "2                NaN            NaN  \n",
      "3                NaN            NaN  \n",
      "4                NaN            NaN  \n",
      "...              ...            ...  \n",
      "25092            NaN            NaN  \n",
      "25093            NaN            NaN  \n",
      "25094            NaN            NaN  \n",
      "25095            NaN            NaN  \n",
      "25096            NaN            NaN  \n",
      "\n",
      "[25097 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "# move the sentence number column to the front\n",
    "# adapted from: https://stackoverflow.com/questions/25122099/move-column-by-name-to-front-of-table-in-pandas\n",
    "cols = list(test_df)\n",
    "cols.insert(0,cols.pop(cols.index('Sent_ID')))\n",
    "test_df = test_df.loc[:,cols]\n",
    "# fill NaN values for all tokens that are not at the beginning of the sentence\n",
    "test_df.Sent_ID.ffill(inplace=True)\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by sentences\n",
    "sentences_test = test_df.groupby(['Sent_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the new df to store splitted data in\n",
    "# start with the first sentence (based on the fact that we know it only has one predicate in it)\n",
    "first = sentences_test.get_group(1)\n",
    "pred = first['UP:PRED'].nunique()\n",
    "new_test = first.filter(items=header_split_df)\n",
    "new_test['UP:ARGHEADS'] = first['UP:ARGHEADS_1']\n",
    "# print(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through grouped sentences\n",
    "for name, sentence in sentences_test:\n",
    "    if name == 1: # skip the first sentence\n",
    "        continue\n",
    "    predicates = sentence['UP:PRED'].nunique()\n",
    "    if predicates <= 2:\n",
    "        sentence_df = sentence.filter(items=header_split_df)\n",
    "        sentence_df['UP:ARGHEADS'] = sentence['UP:ARGHEADS_1']\n",
    "        new_test = pd.concat([new_test,sentence_df])\n",
    "    else:\n",
    "        for i in range(predicates-1):\n",
    "            sentence_df = sentence.filter(items=header_split_df)\n",
    "            sentence_df['UP:ARGHEADS'] = sentence[f'UP:ARGHEADS_{i+1}']\n",
    "            new_test = pd.concat([new_test,sentence_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a tsv file\n",
    "new_test.to_csv('../data/test_split.tsv',sep='\\t',header=0,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78a3364465fb50e0bbd2ff723d0ca9779d4996be68a7b6d285d5d9c02e4e35e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
